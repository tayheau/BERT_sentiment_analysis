![bert](bertGIT.png)
# Sentiment Analysis with BERT
This project applies a pre-trained BERT model to classify sentiment based on a dataset containing various emotion labels. The model is fine-tuned and tested for sentiment analysis, with results presented through common evaluation metrics such as accuracy, precision, recall, and F1-score.

## Project Overview
The goal of this project is to implement a sentiment analysis pipeline using BERT (Bidirectional Encoder Representations from Transformers). BERT is a state-of-the-art transformer model designed to handle NLP tasks with exceptional performance. This project focuses on fine-tuning BERT for multi-class sentiment classification, where the labels represent different emotions such as "happy," "angry," "disgust," etc.

## Key Features
  - __Model__: Fine-tuning BERT for emotion classification.
  - __Data Preprocessing__: Tokenization and input transformation using BERTâ€™s tokenizer.
  - __Evaluation__: Reporting precision, recall, F1-score, and accuracy on test data.
  - __Error Analysis__: Analysis of model performance on various emotion classes, with insights into strengths and areas for improvement.

## Results
![results](results.png)
